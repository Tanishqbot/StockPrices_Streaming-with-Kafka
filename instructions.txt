first create the instance
Note: while creating the instance, you need to select Amazon Linux 2 AMI (HVM) .... SSD Volume Type.
Kafka will get stuck at the producer and consumer if above step is not done. 

--------------------------------------------------------


Note: After creating the instance, you need to save the .pem file into C folder under the users to have necessary permissions.
add the .pem ssh file to the command line




----------------------------------------
wget https://downloads.apache.org/kafka/3.3.1/kafka_2.12-3.9.0.tgz
tar -xvf kafka_2.12-3.9.0.tgz


-----------------------
java -version
sudo yum install java-1.8.0-openjdk
java -version
cd kafka_2.12-3.9.0

Start Zoo-keeper:
-------------------------------
bin/zookeeper-server-start.sh config/zookeeper.properties

Open another window to start kafka
But first ssh to to your ec2 machine as done above


Start Kafka-server:
----------------------------------------
Duplicate the session & enter in a new console --
export KAFKA_HEAP_OPTS="-Xmx256M -Xms128M" 
cd kafka_2.12-3.9.0
bin/kafka-server-start.sh config/server.properties

It is pointing to private server , change server.properties so that it can run in public IP 

To do this , you can follow any of the 2 approaches shared belwo --
Do a "sudo nano config/server.properties" - change ADVERTISED_LISTENERS to public ip of the EC2 instance


Create the topic:
-----------------------------
Duplicate the session & enter in a new console --
cd kafka_2.12-3.9.0
bin/kafka-topics.sh --create --topic demo_test1 --bootstrap-server {Put the Public IP of your EC2 Instance:9092} --replication-factor 1 --partitions 1
Note: before creating the topic, you need to change the inbound settings to "All traffic" and "Anywhere-IPv4"
If you dont follow the above step then while creating the topic you will face timeOutException.

Start Producer:
--------------------------
bin/kafka-console-producer.sh --topic demo_test1 --bootstrap-server {Put the Public IP of your EC2 Instance:9092} 

Start Consumer:
-------------------------
Duplicate the session & enter in a new console --
cd kafka_2.12-3.9.0
bin/kafka-console-consumer.sh --topic demo_test1 --bootstrap-server {Put the Public IP of your EC2 Instance:9092}

---------------------------------

Create S3 buckets
create access keys and save the csv file
connect the aws CLI with you local system by using - $ aws configure

-----------------------------------

Go to aws Glue
create the crawler
inside that create a database
Go the athena select the database and use it to query the data.
